{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a9dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"CreditCardFraudDetection\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df = spark.read.csv(\"creditcard.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1ac768",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ['Class']]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features_unscaled\")\n",
    "scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2f3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformed = pipeline.fit(df).transform(df)\n",
    "\n",
    "final_df = df_transformed.select(\"features\", col(\"Class\").alias(\"label\"))\n",
    "pandas_df = final_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76550d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import databricks.connect as db_connect\n",
    "import mlflow.tracking._model_registry.utils\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Workaround to set the registry URI manually\n",
    "mlflow.tracking._model_registry.utils._get_registry_uri_from_spark_session = lambda: \"databricks-uc\"\n",
    "\n",
    "mlflow.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(pandas_df[\"features\"].values)\n",
    "y = pandas_df[\"label\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e66ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    n_estimators = 100\n",
    "    max_depth = 8\n",
    "    random_state = 42\n",
    "\n",
    "\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=random_state)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "    mlflow.log_metric(\"precision\", report['1']['precision'])\n",
    "    mlflow.log_metric(\"recall\", report['1']['recall'])\n",
    "    mlflow.log_metric(\"f1_score\", report['1']['f1-score'])\n",
    "\n",
    "    mlflow.sklearn.log_model(clf, \"random_forest_model\")\n",
    "\n",
    "    print(\"Run logged under run_id:\", mlflow.active_run().info.run_id)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
